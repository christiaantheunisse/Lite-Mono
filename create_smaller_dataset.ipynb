{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d8b5b6",
   "metadata": {},
   "source": [
    "# Create smaller dataset\n",
    "This file returns a subset of the original Eigen dataset, where the following conditions are met:\n",
    "- Same distribution of the sampled images over the 28 scenes as the dataset constructed by the Eigen et al. \n",
    "- The right and left image from a stereo image set are never both selected to increase the variance.\n",
    "- Even distribution of images taken by the left and right camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c4fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# Import the txt file with the image names in the training set\n",
    "with open('splits/eigen_zhou/train_files.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd78f80",
   "metadata": {},
   "source": [
    "#### Obtain the different scenes in the Eigen training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9e9ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The scenes in the eigen training split:',\n",
       " ['2011_09_26_drive_0022_sync',\n",
       "  '2011_09_29_drive_0026_sync',\n",
       "  '2011_09_26_drive_0087_sync',\n",
       "  '2011_09_30_drive_0028_sync',\n",
       "  '2011_10_03_drive_0034_sync',\n",
       "  '2011_10_03_drive_0042_sync',\n",
       "  '2011_09_26_drive_0061_sync',\n",
       "  '2011_09_26_drive_0091_sync',\n",
       "  '2011_09_30_drive_0033_sync',\n",
       "  '2011_09_29_drive_0004_sync',\n",
       "  '2011_09_26_drive_0051_sync',\n",
       "  '2011_09_26_drive_0014_sync',\n",
       "  '2011_09_26_drive_0032_sync',\n",
       "  '2011_09_26_drive_0028_sync',\n",
       "  '2011_09_26_drive_0039_sync',\n",
       "  '2011_09_26_drive_0018_sync',\n",
       "  '2011_09_26_drive_0104_sync',\n",
       "  '2011_09_26_drive_0070_sync',\n",
       "  '2011_09_30_drive_0034_sync',\n",
       "  '2011_09_26_drive_0001_sync',\n",
       "  '2011_09_30_drive_0020_sync',\n",
       "  '2011_09_26_drive_0005_sync',\n",
       "  '2011_09_26_drive_0095_sync',\n",
       "  '2011_09_26_drive_0015_sync',\n",
       "  '2011_09_26_drive_0035_sync',\n",
       "  '2011_09_26_drive_0113_sync',\n",
       "  '2011_09_26_drive_0019_sync',\n",
       "  '2011_09_26_drive_0011_sync',\n",
       "  '2011_09_28_drive_0001_sync',\n",
       "  '2011_09_26_drive_0079_sync',\n",
       "  '2011_09_26_drive_0057_sync',\n",
       "  '2011_09_26_drive_0017_sync'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes = []\n",
    "for line in lines:\n",
    "    data = line[11:37]\n",
    "    if data not in scenes:\n",
    "        scenes.append(data)\n",
    "\n",
    "\"The scenes in the eigen training split:\", scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a690b0",
   "metadata": {},
   "source": [
    "#### Number of images from the left and right camera. Is approximately the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d111a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left: 19956, right: 19854'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of left and right images\n",
    "l, r = 0, 0\n",
    "for line in lines:\n",
    "    data = line[-2:-1]\n",
    "    if data == 'l':\n",
    "        l += 1\n",
    "    elif data == 'r':\n",
    "        r += 1\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        \n",
    "f\"left: {l}, right: {r}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0c8b1",
   "metadata": {},
   "source": [
    "#### Store the images and number of images per scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a70a5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The number of images used per scene. Some scenes have much more recordings than others:',\n",
       " {'2011_09_26_drive_0022_sync': 1427,\n",
       "  '2011_09_29_drive_0026_sync': 48,\n",
       "  '2011_09_26_drive_0087_sync': 1296,\n",
       "  '2011_09_30_drive_0028_sync': 9287,\n",
       "  '2011_10_03_drive_0034_sync': 8413,\n",
       "  '2011_10_03_drive_0042_sync': 1994,\n",
       "  '2011_09_26_drive_0061_sync': 1268,\n",
       "  '2011_09_26_drive_0091_sync': 594,\n",
       "  '2011_09_30_drive_0033_sync': 2873,\n",
       "  '2011_09_29_drive_0004_sync': 570,\n",
       "  '2011_09_26_drive_0051_sync': 547,\n",
       "  '2011_09_26_drive_0014_sync': 549,\n",
       "  '2011_09_26_drive_0032_sync': 700,\n",
       "  '2011_09_26_drive_0028_sync': 783,\n",
       "  '2011_09_26_drive_0039_sync': 701,\n",
       "  '2011_09_26_drive_0018_sync': 198,\n",
       "  '2011_09_26_drive_0104_sync': 565,\n",
       "  '2011_09_26_drive_0070_sync': 757,\n",
       "  '2011_09_30_drive_0034_sync': 2009,\n",
       "  '2011_09_26_drive_0001_sync': 189,\n",
       "  '2011_09_30_drive_0020_sync': 1984,\n",
       "  '2011_09_26_drive_0005_sync': 263,\n",
       "  '2011_09_26_drive_0095_sync': 476,\n",
       "  '2011_09_26_drive_0015_sync': 535,\n",
       "  '2011_09_26_drive_0035_sync': 233,\n",
       "  '2011_09_26_drive_0113_sync': 151,\n",
       "  '2011_09_26_drive_0019_sync': 769,\n",
       "  '2011_09_26_drive_0011_sync': 210,\n",
       "  '2011_09_28_drive_0001_sync': 161,\n",
       "  '2011_09_26_drive_0079_sync': 140,\n",
       "  '2011_09_26_drive_0057_sync': 113,\n",
       "  '2011_09_26_drive_0017_sync': 7})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store images per scene\n",
    "scenes_count = dict()\n",
    "scenes_images = dict()\n",
    "for line in lines:\n",
    "    scene = line[11:37]\n",
    "    try:\n",
    "        scenes_count[scene] += 1\n",
    "        scenes_images[scene].append(line)\n",
    "    except:\n",
    "        scenes_count[scene] = 1\n",
    "        scenes_images[scene] = [line]\n",
    "        \n",
    "\"The number of images used per scene. Some scenes have much more recordings than others:\", scenes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e254c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove left or right image if both exist for a certain timestamp\n",
    "scenes_images_s = scenes_images.copy()\n",
    "scenes_count_s = dict()\n",
    "for images in scenes_images_s.values():\n",
    "    for im in images:\n",
    "        if im[-2:-1] == 'r':\n",
    "            inverse = im[:-2] + 'l\\n'\n",
    "        else:\n",
    "            inverse = im[:-2] + 'r\\n'\n",
    "        if inverse in images:\n",
    "            images.remove(random.choice([im, inverse]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dbdfc2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Total images in new training data set: 9950',\n",
       " 'Number of training images per scene in new dataset',\n",
       " {'2011_09_26_drive_0022_sync': 357,\n",
       "  '2011_09_29_drive_0026_sync': 12,\n",
       "  '2011_09_26_drive_0087_sync': 324,\n",
       "  '2011_09_30_drive_0028_sync': 2322,\n",
       "  '2011_10_03_drive_0034_sync': 2103,\n",
       "  '2011_10_03_drive_0042_sync': 498,\n",
       "  '2011_09_26_drive_0061_sync': 317,\n",
       "  '2011_09_26_drive_0091_sync': 148,\n",
       "  '2011_09_30_drive_0033_sync': 718,\n",
       "  '2011_09_29_drive_0004_sync': 142,\n",
       "  '2011_09_26_drive_0051_sync': 137,\n",
       "  '2011_09_26_drive_0014_sync': 137,\n",
       "  '2011_09_26_drive_0032_sync': 175,\n",
       "  '2011_09_26_drive_0028_sync': 196,\n",
       "  '2011_09_26_drive_0039_sync': 175,\n",
       "  '2011_09_26_drive_0018_sync': 50,\n",
       "  '2011_09_26_drive_0104_sync': 141,\n",
       "  '2011_09_26_drive_0070_sync': 189,\n",
       "  '2011_09_30_drive_0034_sync': 502,\n",
       "  '2011_09_26_drive_0001_sync': 47,\n",
       "  '2011_09_30_drive_0020_sync': 496,\n",
       "  '2011_09_26_drive_0005_sync': 66,\n",
       "  '2011_09_26_drive_0095_sync': 119,\n",
       "  '2011_09_26_drive_0015_sync': 134,\n",
       "  '2011_09_26_drive_0035_sync': 58,\n",
       "  '2011_09_26_drive_0113_sync': 38,\n",
       "  '2011_09_26_drive_0019_sync': 192,\n",
       "  '2011_09_26_drive_0011_sync': 52,\n",
       "  '2011_09_28_drive_0001_sync': 40,\n",
       "  '2011_09_26_drive_0079_sync': 35,\n",
       "  '2011_09_26_drive_0057_sync': 28,\n",
       "  '2011_09_26_drive_0017_sync': 2})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select 1/4 of all the images in every scene\n",
    "total_selected = 0\n",
    "new_scenes_images, new_scenes_count = dict(), dict()\n",
    "for scene in scenes:\n",
    "    select_no = round(scenes_count[scene] / 4)\n",
    "    new_scenes_images[scene] = random.choices(scenes_images_s[scene], k=select_no)\n",
    "    new_scenes_count[scene] = select_no\n",
    "    total_selected += select_no\n",
    "    \n",
    "f\"Total images in new training data set: {total_selected}\", \\\n",
    "\"Number of training images per scene in new dataset\", \\\n",
    "new_scenes_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfba80",
   "metadata": {},
   "source": [
    "#### Create a new txt file with the shuffled list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844cbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_lines = list(itertools.chain.from_iterable(new_scenes_images.values()))\n",
    "random.shuffle(new_training_lines)\n",
    "    \n",
    "with open('splits/eigen_reduced/training_files.txt', 'w') as f:\n",
    "    for line in new_training_lines:  \n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e87bf1",
   "metadata": {},
   "source": [
    "## Do the same for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1001aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the txt file with the image names in the validation set\n",
    "with open('splits/eigen_zhou/val_files.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Obtain the scenes\n",
    "scenes = []\n",
    "for line in lines:\n",
    "    data = line[11:37]\n",
    "    if data not in scenes:\n",
    "        scenes.append(data)\n",
    "\n",
    "# Store images per scene\n",
    "scenes_count = dict()\n",
    "scenes_images = dict()\n",
    "for line in lines:\n",
    "    scene = line[11:37]\n",
    "    try:\n",
    "        scenes_count[scene] += 1\n",
    "        scenes_images[scene].append(line)\n",
    "    except:\n",
    "        scenes_count[scene] = 1\n",
    "        scenes_images[scene] = [line]\n",
    "        \n",
    "# Remove left or right image if both exist for a certain timestamp\n",
    "scenes_images_s = scenes_images.copy()\n",
    "scenes_count_s = dict()\n",
    "for images in scenes_images_s.values():\n",
    "    for im in images:\n",
    "        if im[-2:-1] == 'r':\n",
    "            inverse = im[:-2] + 'l\\n'\n",
    "        else:\n",
    "            inverse = im[:-2] + 'r\\n'\n",
    "        if inverse in images:\n",
    "            images.remove(random.choice([im, inverse]))\n",
    "            \n",
    "# select 1/4 of all the images in every scene\n",
    "new_scenes_images, new_scenes_count = dict(), dict()\n",
    "for scene in scenes:\n",
    "    select_no = round(scenes_count[scene] / 4)\n",
    "    new_scenes_images[scene] = random.choices(scenes_images_s[scene], k=select_no)\n",
    "    new_scenes_count[scene] = select_no\n",
    "\n",
    "new_validation_lines = list(itertools.chain.from_iterable(new_scenes_images.values()))\n",
    "random.shuffle(new_validation_lines)\n",
    "\n",
    "with open('splits/eigen_reduced/val_files.txt', 'w') as f:\n",
    "    for line in new_validation_lines:  \n",
    "        f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
